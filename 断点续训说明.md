# æ–­ç‚¹ç»­è®­ä½¿ç”¨æŒ‡å—

## ğŸ”„ åŠŸèƒ½è¯´æ˜

è®­ç»ƒè„šæœ¬å·²å†…ç½®**è‡ªåŠ¨æ–­ç‚¹ç»­è®­**åŠŸèƒ½ï¼Œå½“è®­ç»ƒå› ä¸ºä»¥ä¸‹åŸå› ä¸­æ–­æ—¶ï¼š
- æœåŠ¡å™¨æ—¶é—´é™åˆ¶ï¼ˆTime Limitï¼‰
- æ‰‹åŠ¨ä¸­æ–­ï¼ˆCtrl+Cï¼‰
- ç³»ç»Ÿæ•…éšœ
- å…¶ä»–æ„å¤–ä¸­æ–­

åªéœ€é‡æ–°è¿è¡Œ `python main.py`ï¼Œè®­ç»ƒä¼š**è‡ªåŠ¨ä»æœ€æ–°checkpointç»§ç»­**ï¼Œæ— éœ€ä»»ä½•é¢å¤–é…ç½®ï¼

---

## ğŸ“ Checkpoint ä¿å­˜ç­–ç•¥

### ä¿å­˜é¢‘ç‡
- **æ¯ 1000 æ­¥**ä¿å­˜ä¸€æ¬¡ checkpointï¼ˆçº¦ **15 åˆ†é’Ÿ**ï¼‰
- **åªä¿ç•™æœ€è¿‘ 3 ä¸ª** checkpointï¼ˆèŠ‚çœç£ç›˜ç©ºé—´ï¼‰

### Checkpoint ä½ç½®
```
./results/
â”œâ”€â”€ checkpoint-1000/    # Step 1000 çš„checkpoint
â”œâ”€â”€ checkpoint-2000/    # Step 2000 çš„checkpoint
â””â”€â”€ checkpoint-3000/    # Step 3000 çš„checkpoint (æœ€æ–°)
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æƒ…å†µ1ï¼šé¦–æ¬¡è®­ç»ƒ

```bash
cd ~/A2_final
conda activate A2_final
python main.py
```

è¾“å‡ºï¼š
```
ğŸ†• å¼€å§‹æ–°çš„è®­ç»ƒ
```

### æƒ…å†µ2ï¼šè®­ç»ƒä¸­æ–­åç»§ç»­

```bash
cd ~/A2_final
conda activate A2_final
python main.py  # ç›¸åŒçš„å‘½ä»¤ï¼
```

è¾“å‡ºï¼š
```
ğŸ”„ æ£€æµ‹åˆ°checkpoint: checkpoint-20000
   å°†ä»æ­¤å¤„ç»§ç»­è®­ç»ƒ...
âœ… ä»checkpointæ¢å¤è®­ç»ƒ
```

**å®Œå…¨è‡ªåŠ¨ï¼** è®­ç»ƒä¼šä»ä¸­æ–­çš„åœ°æ–¹ç»§ç»­ï¼ŒåŒ…æ‹¬ï¼š
- âœ… æ¨¡å‹æƒé‡
- âœ… ä¼˜åŒ–å™¨çŠ¶æ€
- âœ… å­¦ä¹ ç‡è°ƒåº¦å™¨
- âœ… è®­ç»ƒæ­¥æ•°å’Œepoch
- âœ… éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€

---

## ğŸ’¾ Checkpoint å†…å®¹

æ¯ä¸ª checkpoint åŒ…å«ï¼š

```
checkpoint-1000/
â”œâ”€â”€ model.safetensors          # æ¨¡å‹æƒé‡
â”œâ”€â”€ optimizer.pt               # ä¼˜åŒ–å™¨çŠ¶æ€
â”œâ”€â”€ scheduler.pt               # å­¦ä¹ ç‡è°ƒåº¦å™¨
â”œâ”€â”€ trainer_state.json         # è®­ç»ƒçŠ¶æ€ï¼ˆæ­¥æ•°ã€epochç­‰ï¼‰
â”œâ”€â”€ training_args.bin          # è®­ç»ƒå‚æ•°
â””â”€â”€ rng_state.pth             # éšæœºæ•°çŠ¶æ€
```

---

## ğŸ¯ æœåŠ¡å™¨æ—¶é—´é™åˆ¶åº”å¯¹ç­–ç•¥

### é—®é¢˜
æœåŠ¡å™¨é€šå¸¸æœ‰è¿è¡Œæ—¶é—´é™åˆ¶ï¼ˆå¦‚2å°æ—¶ï¼‰ï¼Œè€Œå®Œæ•´è®­ç»ƒéœ€è¦3-4å°æ—¶ã€‚

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1ï¼šåˆ†æ‰¹è®­ç»ƒï¼ˆæ¨èï¼‰

```bash
# ç¬¬ä¸€æ¬¡è¿è¡Œï¼ˆä¼šåœ¨2å°æ—¶æ—¶è¢«ä¸­æ–­ï¼‰
srun -p gpu --gres=gpu:1 --time=02:00:00 python main.py

# ç­‰ä»»åŠ¡è¢«ä¸­æ–­åï¼Œç«‹å³é‡æ–°è¿è¡Œ
srun -p gpu --gres=gpu:1 --time=02:00:00 python main.py

# å¦‚æœè¿˜æ²¡å®Œæˆï¼Œå†æ¬¡è¿è¡Œ
srun -p gpu --gres=gpu:1 --time=02:00:00 python main.py
```

#### æ–¹æ¡ˆ2ï¼šä½¿ç”¨ while å¾ªç¯è‡ªåŠ¨é‡è¯•

åˆ›å»ºè„šæœ¬ `auto_train.sh`:

```bash
#!/bin/bash
# è‡ªåŠ¨é‡è¯•è®­ç»ƒè„šæœ¬

MAX_ATTEMPTS=5
ATTEMPT=1

while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
    echo "å°è¯• $ATTEMPT / $MAX_ATTEMPTS"
    
    # è¿è¡Œè®­ç»ƒï¼ˆ2å°æ—¶é™åˆ¶ï¼‰
    srun -p gpu --gres=gpu:1 --time=02:00:00 python main.py
    
    # æ£€æŸ¥æ˜¯å¦å®Œæˆï¼ˆæŸ¥çœ‹æ˜¯å¦æœ‰final_modelï¼‰
    if [ -f "./results/pytorch_model.bin" ]; then
        echo "âœ… è®­ç»ƒå®Œæˆï¼"
        break
    fi
    
    echo "â¸ï¸ è®­ç»ƒä¸­æ–­ï¼Œ15ç§’åé‡æ–°å¼€å§‹..."
    sleep 15
    ATTEMPT=$((ATTEMPT + 1))
done
```

ä½¿ç”¨æ–¹æ³•ï¼š
```bash
chmod +x auto_train.sh
./auto_train.sh
```

---

## ğŸ“Š æŸ¥çœ‹è®­ç»ƒè¿›åº¦

### æ–¹æ³•1ï¼šæŸ¥çœ‹æœ€æ–° checkpoint

```bash
ls -lth results/checkpoint-*/
```

æœ€æ–°çš„ checkpoint ç¼–å· = å½“å‰è®­ç»ƒæ­¥æ•°

### æ–¹æ³•2ï¼šæŸ¥çœ‹è®­ç»ƒæ—¥å¿—

```bash
tail -f results/trainer_state.json
```

æŸ¥çœ‹ `global_step` å’Œ `epoch` å­—æ®µï¼š
```json
{
  "global_step": 20000,
  "epoch": 0.66,
  "total_steps": 93750
}
```

**è¿›åº¦è®¡ç®—**ï¼š20000 / 93750 = 21.3% å®Œæˆ

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### âœ… å¯ä»¥åšçš„ï¼š

1. **éšæ—¶ä¸­æ–­è®­ç»ƒ**
   - Ctrl+C æˆ–æœåŠ¡å™¨è¶…æ—¶éƒ½æ²¡é—®é¢˜
   
2. **ä¿®æ”¹è®­ç»ƒå‚æ•°åç»§ç»­**
   - ä¿®æ”¹ `learning_rate`ã€`batch_size` ç­‰
   - ä½†ä¼šä»checkpointçš„**åŸå§‹å‚æ•°**ç»§ç»­

3. **åˆ é™¤æ—§ checkpoint èŠ‚çœç©ºé—´**
   ```bash
   rm -rf results/checkpoint-1000
   ```

### âŒ ä¸è¦åšçš„ï¼š

1. **ä¸è¦åˆ é™¤ `results/` æ–‡ä»¶å¤¹**
   - ä¼šä¸¢å¤±æ‰€æœ‰è¿›åº¦

2. **ä¸è¦æ‰‹åŠ¨ä¿®æ”¹ checkpoint æ–‡ä»¶**
   - å¯èƒ½å¯¼è‡´æ— æ³•æ¢å¤

3. **ä¸è¦åœ¨ä¸åŒæœºå™¨é—´å¤åˆ¶ checkpoint**
   - å¯èƒ½æœ‰ç¯å¢ƒå·®å¼‚ï¼Œå»ºè®®åœ¨åŒä¸€æœåŠ¡å™¨ä¸Šç»§ç»­

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šæ— æ³•æ‰¾åˆ° checkpoint

**ç°è±¡**ï¼š
```
ğŸ†• å¼€å§‹æ–°çš„è®­ç»ƒ
```

**åŸå› **ï¼š
- `results/` æ–‡ä»¶å¤¹ä¸å­˜åœ¨æˆ–è¢«åˆ é™¤
- checkpoint æ–‡ä»¶å¤¹å‘½åä¸æ­£ç¡®

**è§£å†³**ï¼š
```bash
ls results/  # æ£€æŸ¥æ˜¯å¦æœ‰checkpointç›®å½•
```

### é—®é¢˜2ï¼šä» checkpoint æ¢å¤å¤±è´¥

**ç°è±¡**ï¼š
```
Error loading checkpoint...
```

**åŸå› **ï¼š
- checkpoint æ–‡ä»¶æŸå
- PyTorch/Transformers ç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³**ï¼š
```bash
# åˆ é™¤æŸåçš„checkpoint
rm -rf results/checkpoint-XXXXX

# ä»æ›´æ—©çš„checkpointç»§ç»­
python main.py  # ä¼šè‡ªåŠ¨æ‰¾åˆ°æ¬¡æ–°çš„checkpoint
```

### é—®é¢˜3ï¼šè®­ç»ƒä»å¤´å¼€å§‹è€Œä¸æ˜¯ç»§ç»­

**åŸå› **ï¼š
- `main.py` ä»£ç è¢«ä¿®æ”¹
- ç¯å¢ƒå˜é‡é—®é¢˜

**æ£€æŸ¥**ï¼š
```bash
# ç¡®è®¤ main.py åŒ…å«æ–­ç‚¹ç»­è®­ä»£ç 
grep "resume_from_checkpoint" main.py
```

---

## ğŸ“ˆ é¢„æœŸè®­ç»ƒæ—¶é—´

åŸºäºå½“å‰é…ç½®ï¼ˆ2Mæ ·æœ¬ï¼Œ3 epochsï¼ŒRTX 4080Sï¼‰ï¼š

| Checkpoint | é¢„è®¡æ—¶é—´ | ç´¯è®¡æ—¶é—´ | å®Œæˆåº¦ |
|-----------|---------|---------|--------|
| checkpoint-10000 | 15åˆ†é’Ÿ | 15åˆ†é’Ÿ | 10.7% |
| checkpoint-20000 | 15åˆ†é’Ÿ | 30åˆ†é’Ÿ | 21.3% |
| checkpoint-40000 | 30åˆ†é’Ÿ | 1å°æ—¶ | 42.7% |
| checkpoint-60000 | 30åˆ†é’Ÿ | 1.5å°æ—¶ | 64.0% |
| checkpoint-80000 | 30åˆ†é’Ÿ | 2å°æ—¶ | 85.3% |
| **å®Œæˆ** | 20åˆ†é’Ÿ | **~2.5å°æ—¶** | 100% |

**å»ºè®®**ï¼šæ¯2å°æ—¶æäº¤ä¸€æ¬¡ä»»åŠ¡ï¼Œç¡®ä¿è‡³å°‘ä¿å­˜2ä¸ªcheckpointã€‚

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å®šæœŸæ£€æŸ¥è¿›åº¦**
   ```bash
   tail results/trainer_state.json
   ```

2. **ç›‘æ§ç£ç›˜ç©ºé—´**
   ```bash
   du -sh results/
   ```
   æ¯ä¸ª checkpoint çº¦ **1.2GB**

3. **å¤‡ä»½é‡è¦ checkpoint**
   ```bash
   cp -r results/checkpoint-50000 ~/backup/
   ```

4. **è®­ç»ƒå®Œæˆåæ¸…ç†**
   ```bash
   # åªä¿ç•™æœ€ç»ˆæ¨¡å‹ï¼Œåˆ é™¤ä¸­é—´checkpoint
   rm -rf results/checkpoint-*
   ```

---

## ğŸ“ æŠ€æœ¯ç»†èŠ‚

æ–­ç‚¹ç»­è®­åŸºäº Hugging Face Transformers çš„å†…ç½®åŠŸèƒ½ï¼š

```python
# main.py ä¸­çš„å…³é”®ä»£ç 
resume_from_checkpoint = get_latest_checkpoint(OUTPUT_DIR)
trainer.train(resume_from_checkpoint=resume_from_checkpoint)
```

ä¼˜ç‚¹ï¼š
- âœ… å®Œå…¨æ¢å¤è®­ç»ƒçŠ¶æ€
- âœ… Loss æ›²çº¿è¿ç»­ï¼Œæ— è·³è·ƒ
- âœ… è®­ç»ƒæ—¶é—´ç´¯åŠ å‡†ç¡®
- âœ… æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œæ£€æŸ¥ï¼š

1. `results/` æ–‡ä»¶å¤¹æƒé™
2. ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³
3. PyTorch ç‰ˆæœ¬æ˜¯å¦åŒ¹é…
4. æ˜¯å¦åœ¨æ­£ç¡®çš„ conda ç¯å¢ƒä¸­

**Happy Training!** ğŸš€
