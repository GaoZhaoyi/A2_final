# RTX 4080S (16GB) 专用配置说明

## 🎯 目标配置
- **硬件**: RTX 4080S (16GB显存)
- **系统**: Linux
- **目标时间**: 约4小时
- **目标BLEU**: ≥25

## ⚙️ 关键优化

### 1. 训练参数优化
```python
# trainer.py中的关键设置
num_train_epochs=2                    # 2轮训练（相比原来的3轮）
per_device_train_batch_size=24        # RTX 4080S优化的批次大小
gradient_accumulation_steps=4         # 有效批次 = 96
learning_rate=8e-5                    # 更高LR加快收敛
warmup_ratio=0.06                     # 减少预热加快训练
bf16=True                             # RTX 4080S首选BF16
optim="adamw_torch_fused"             # 融合优化器更快
dataloader_num_workers=8              # Linux下多进程加载
```

### 2. 数据集优化
```python
# dataset.py中的设置
WMT19训练样本: 500万（从2400万减少）
OPUS-100样本: 50万（精选高质量）
总训练样本: 约550万
```

### 3. BF16 vs FP16
**为什么选择BF16？**
- RTX 4080S (Ada架构) 对BF16有硬件加速
- BF16数值稳定性更好，无需loss scaling
- 训练速度与FP16相当或更快
- 更少的数值溢出问题

## 📊 预期性能

### 时间估算
| 阶段 | 时间 | BLEU |
|------|------|------|
| 第1轮 | 0-2小时 | 约23-24 |
| 第2轮 | 2-4小时 | 约25-27 |
| **总计** | **约3.5-4小时** | **25-27** |

### 显存使用
- **训练峰值**: 约14-15GB
- **评估峰值**: 约12-13GB
- **安全裕度**: 1-2GB（适合16GB显存）

### 吞吐量估算
```
批次大小: 24
梯度累积: 4步
有效批次: 96样本/更新
总样本: 550万
每轮步数: 约57,000步
两轮总步数: 约114,000步

RTX 4080S速度: 约8样本/秒
预计时间: 114,000步 × 96样本 / 8样本/秒 / 3600秒 ≈ 3.8小时
```

## 🚀 运行步骤

### 1. 环境检查
```bash
# 检查CUDA和PyTorch
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, BF16: {torch.cuda.is_bf16_supported()}')"

# 应该输出: CUDA: True, BF16: True
```

### 2. 测试设置
```bash
python test_setup.py
```

### 3. 开始训练
```bash
# 标准运行
python main.py

# 后台运行（推荐）
nohup python main.py > training.log 2>&1 &

# 监控GPU
watch -n 1 nvidia-smi
```

### 4. 监控进度
```bash
# 查看日志
tail -f training.log

# 或直接查看结果目录
ls -lh results/
```

## 💡 显存优化技巧

### 如果显存不足（OOM）
编辑 `trainer.py`:
```python
per_device_train_batch_size=16,      # 从24减少到16
gradient_accumulation_steps=6,        # 从4增加到6
```
这会略微降低速度但不影响最终效果。

### 如果显存充足（>2GB剩余）
可以尝试：
```python
per_device_train_batch_size=32,      # 从24增加到32
gradient_accumulation_steps=3,        # 从4减少到3
```
这可能再节省15-20分钟。

## 📈 预期BLEU分数轨迹

```
步数 0:      BLEU ~0
步数 2000:   BLEU ~18-20
步数 10000:  BLEU ~22-23
步数 30000:  BLEU ~23-24  <- 第1轮结束
步数 60000:  BLEU ~24-25
步数 90000:  BLEU ~25-26
步数 114000: BLEU ~25-27  <- 第2轮结束（最终）
```

## 🔧 Linux特定优化

### 1. 系统设置
```bash
# 设置进程优先级
nice -n -10 python main.py

# 或使用更高优先级（需要root）
sudo nice -n -20 python main.py
```

### 2. 数据加载优化
代码中已设置：
- `dataloader_num_workers=8`: 多进程数据加载
- `dataloader_pin_memory=True`: 固定内存加速传输

### 3. 磁盘I/O优化
确保数据集缓存在SSD上：
```bash
# 设置HuggingFace缓存目录
export HF_HOME=/path/to/ssd/.cache/huggingface
export HF_DATASETS_CACHE=/path/to/ssd/.cache/huggingface/datasets
```

## 🎯 性能对比

| 配置 | 训练时间 | 显存 | BLEU | 适用 |
|------|----------|------|------|------|
| **当前配置** | **3.5-4h** | **14-15GB** | **25-27** | **RTX 4080S** |
| 原始配置 | 8-10h | 20-24GB | 26-28 | V100/A100 |
| 保守配置 | 5-6h | 12-14GB | 24-26 | RTX 3090 |

## ⚠️ 注意事项

### 1. 温度监控
RTX 4080S在长时间训练时会发热，建议：
```bash
# 监控温度
watch -n 2 nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader

# 如果温度>85°C，考虑：
# - 改善机箱散热
# - 设置功率限制：sudo nvidia-smi -pl 250
```

### 2. 电源管理
```bash
# 设置性能模式
sudo nvidia-smi -pm 1

# 设置最大时钟频率
sudo nvidia-smi -lgc 2610
```

### 3. 后台运行最佳实践
```bash
# 使用screen或tmux
screen -S training
python main.py
# Ctrl+A, D 分离会话

# 重新连接
screen -r training
```

## 📝 快速检查清单

训练前确认：
- [ ] CUDA可用且支持BF16
- [ ] 显存至少有15GB可用
- [ ] 已运行test_setup.py无错
- [ ] 磁盘空间>50GB
- [ ] 网络畅通（首次下载数据）
- [ ] 系统不会自动休眠/关机

训练中监控：
- [ ] GPU利用率>90%
- [ ] 温度<85°C
- [ ] 显存使用稳定在14-15GB
- [ ] 每100步有日志输出
- [ ] BLEU分数稳步上升

## 🎉 预期结果

完成训练后，你应该看到：
```
Test Metrics: {'test_bleu': 25.x - 27.x, ...}
```

如果BLEU ≥ 25，恭喜！你已达到90-100%的成绩标准！

## 📞 故障排查

**Q: 训练速度比预期慢？**
A: 检查GPU利用率，确保dataloader_num_workers=8且数据在SSD上

**Q: 显存溢出？**
A: 减少batch_size到16或20

**Q: BF16报错？**
A: 确认PyTorch版本≥1.10，改用fp16=True

**Q: 4小时后未完成？**
A: 可能数据加载慢，检查磁盘I/O和网络

**Q: BLEU低于预期？**
A: 确保训练完成2轮，检查日志是否有错误
